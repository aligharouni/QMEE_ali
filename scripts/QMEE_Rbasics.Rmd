---
title: "QMEE 2021"
author: "Ali"
date: "14/01/2021"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Calss 1 
- R basics

```{r}
x <- 1
## vector
words <- c("hello", "a")
v <- 1:5
xx <- c(1,"hello") ## ? coercion
str(xx)
## turned 1 to a char to make them the same type

## lists
L <- list(1,"hello")
L[[1]]


```

## Calss 2

- we are going to continue intro to R
- then github with JD

```{r intro to R}
x <- c(2,3,1)
y <- c(2,2,6)
t.test(x,y,var.equal=T)

# R is case sensative m and M are diff
# tab is your friend, type v and tab and R shows you everything starts with v
# no space in var name, what is the best var name? not long, long enough
# Read the style points in the course page

# we talked about vector and lists, more complicated objects

# dataframe, list of columns, each col is a vector, rows are observations
dd <- data.frame(a=1:3,b=c("hello", "good", "bad"))

factor(c("sparrow","robin","bat"))## is different from c()
species <- c("sparrow","robin","bat")
# Note: most of variables are numerics or factors
# another kind of dataframe called tibble

## Loops
 v<- 1:5
for(x in v){
  if(x>=4)
    print(x^2)
}

 ## Logical
 x=1
  x!=2 ## bang
  x==1 & 3==5
 x==1 | 3==5
 species == "robin" ## is applied to the whole vector

 # we want to refer to a specific element
 species[2]
 # a row from a df, several ways:
 dd[["a"]]
 dd$a ## shortcut
 dd[[1]] ## refering to element by position

# ########################################
## The tidyverse (by Hadly Wicom)
# ########################################
 library(tidyverse)
 # a set of packages, can be easier to do complicated things, speed
 # disadvantages: instability with base R
 # where are you putting your stuff, data
 getwd()
 dir.create("data") ## make sure you are in the dir of your course where you want to creat a data dir
 download.file(url="https://ndownloader.figshare.com/files/2292169",
               destfile = "data/newdata.csv")

 surveys <- read_csv("data/newdata.csv")
## it is a tibble
 head(surveys)

## manipulating data verbs: select (taking col), filter (taking rows), ..
 select(surveys, month, day)
 select(surveys,-genus)


 filter(surveys, (month >11|month<3) & species== "albigula")  ## if you put , in filter it means & &
 ## PIPE

 survey2 <- (surveys
   %>% filter(month >11)
   %>% select(-day)
   %>% mutate(LW=weight/100) ## to change the name of var or creat a new var
 )

 # keyboard shortcut, go to helpyboard shortcut keys
 # %>% ctrl + shift +m

# other verbs; group_by(), summerise()

```

## Calss 3

Date: Jan 21, 2021
see chap 9 and 10 of https://happygitwithr.com/

```{r intro to R class 3}
## villageTable <- read_csv("/data/villageTable.csv")
## where is this data? 

```

## Calss 4 
Date: Jan 26, 2021

- different functions and diff forms that you want to put your data in
- talking about malaria data set
- Data maintenance; tidy data the core of it, into database form that is relational (tibble, dataframe, they know how to connect to each others through ids), long format
- long format; tidy data, make data as clean as possible, break the dataset into different related tables so I can put the data into level I want (individual table, household table, village table, etc), we use keys
- choose your work flow
  - example; tibble (time, S,I,R) from wide format to long format using pivot_longer
  pivot_longer(data, cols=!time , names_to="class", values_to="people") 
    - cols=!time; don't treat time as value variable (! is called Bang)
    - we are treat S I R as same kind and time different
    - result -> columns would be "time,class,people"
  - Importing data;
  - summarize; check the numbers are nums, dates are dates, categorical vars are factors

- How to make relational tables?
  - a table at level of people
  - a table at the level of sampling events,
  - a table 



```{r class_4}
library(tidyverse)

QMEEpath <- "~/classes/QMEE/docs/data/"
list.files(path=QMEEpath, pattern="*.csv") # create list of all .csv files in folder
file_name <- "village.csv"
villageTable <- read_csv(file = paste(QMEEpath,file_name, sep=''))

print(villageTable
      %>% group_by(vname) ## village name
      %>% summarize(count= n())
      %>% filter(count>1)
      )

file_name2 <- "parademo.csv"
parasiteTable <- read_csv(file = paste(QMEEpath,file_name2, sep=''))
print(parasiteTable
      %>%  group_by(id, village, compound)
      %>% summarize(count=n())
      %>% group_by(id)
      %>% summarize(count=n())
      %>% filter(count>1)
      %>% arrange(desc(count))
  
)

```

- correction tables
  - make a table
  - make a dictionary
  
```{r }

download.file(url="https://github.com/mac-theobio/QMEE/blob/master/docs/data/parademo.csv",
               destfile = "data/parademo.csv")

```

## Calss 5
Date: Thursday Jan 28, 2021

```{r jan_28_class}
QMEEpath <- "~/classes/QMEE/docs/data/"
list.files(path=QMEEpath, pattern="*.csv") # create list of all .csv files in folder
file_name <- "village.csv"

village <- read.csv(file = paste(QMEEpath,file_name, sep=''))


apropos("plot") ## find any appropriate plot
head(mtcars) ## this is a built in data set

library(tidyverse)
find("filter") ## the order of packages that R is using function filter
m <- as_tibble(mtcars) ## tibble mostly behave like dataframe, the primary case that makes it different
print(m)
# difference between dataframe and tibble, see below
str(mtcars[,1])
str(m[,1])

m %>% group_by(cyl) ## group it by single var, ie cylender
m %>% group_by(cyl) %>% ungroup() ## group it by cylender and ungroup it

m %>% group_by(cyl) %>% summarise(mpg=mean(mpg))

m %>% group_by(cyl,gear)
m %>% group_by(cyl,gear) %>% summarise(mpg=mean(mpg))

## trick 1, minimum way of putting data into your code
tax_table <- read.csv(text="
common_name, taxon
sunfish, fish
gar, fish
racoon, mamel
                      ")
## trick 2
tax_table2 <- read.csv(sep="|", strip.white=TRUE,
text="
common_name, taxon
sunfish, fish
gar, fish
racoon, mamel
                      ")


```

## Calss 5
Date: Tuesday Feb 2, 2021

Data visualizations, 3 different contexts
- 1 goal is to explore the data, possibly explore the hypothesis
- in ggplot there is some thing 

- Basic Graphing
  - plot() ,...
  - par(mfrow), layout() for multiple plots on a page
  - Latice graphics, abstract, creat obg it can be customized
    xyplot(with type = one or more )
  - ggplot(data, aes(x=,y=,colour=)) Why is it called aesthetics? aesthetics mapping
    - geoms
    - geom_points, geom_lines,...
    - facets; we could show subset of data on panels facet_wrap(free-form wrapping of subplots) and facet_grid(2D grids of subplots)
    - more rules of thumb:
      - flip axes to display labels better (ggplot coord_flip(), or ggstance() package which is not better than ggplot)
      - facet rows> facet col
      - order cat variables meaningfully: forcast::fct_reorder(), forcast::fct_infreq() 
      - hist, bin will effects the shape? there is a trade-off, no good answere. if you have a large data set the density plot is better
      - 

```{r Feb_2_class}

## coefficient plots, summarising a table
# Ben has worked on this a lot; dotwhisker::dwplot

# Basic graphics , goal to  data manipulation and draw pics
# Ben saved it in the repo as class_example.R
# data, or you can read from the repo directly
# https://mac-theobio.github.io/QMEE/data/

## PART 1
library(tidyverse)
packageVersion("tidyr") ## what is the version of pckage I am using?

## using col_types=cols() suppresses the messages about which type is which
## homocide data
QMEEpath <- "~/classes/QMEE/docs/data/"
list.files(path=QMEEpath, pattern="*.csv") # create list of all .csv files in folder
dat <- read_csv(file = paste(QMEEpath,"CA_homicide.csv", sep=''),col_types=cols()) 
## population size in 2011
popdat <- read_csv(file = paste(QMEEpath,"CA_popdat.csv", sep=''),col_types=cols())
# Note that read_csv() in tidyverse has not modified the column names to make them legal R variables names (read.csv() in base R will do that by default: use check.names=FALSE to suppress this)
#  look at dat, ggplot likes the long format
head(dat)

# What if we want combine other information?
# Ali, I think here, since the rows are in a Region order already, we can do the followings otherwise we would need a classification algorithm, right?  

rdat <- tibble(Place=dat$Place,
      Region=c("all",rep("Atlantic",4), ## setup a region vat that can distinguish between Canada, others
               rep("East",2),
               rep("West",4),
               rep("North",3)))
head(rdat)

## convert from wide to long
sdat <- (dat
    %>% pivot_longer(names_to="year",values_to="homicide",-Place,
                     names_transform=list(year=as.numeric)) ##we use names_transform to convert the years back to numeric values
)
head(sdat)

## add region and pop size info to the homocide data
sdat2 <- (sdat %>%
    full_join(rdat,by="Place") %>%
    full_join(popdat,by="Place")
)
## if you don't put by=, full_join will tell you what is common in all 3 dats

## what is fuzzy join?

sdat2 %>%
    group_by(Place) %>%
    summarise(homicide=mean(homicide))
## fancier
sdat2 %>%
    group_by(year) %>%
    summarise(across(homicide,list(mean=mean,sd=sd)))

## One more useful technique is reordering factors (representing categorical variables) in a sensible way. Right now the ‘places’ (provinces, territories, etc.) are ordered alphabetically, R’s default.
str(sdat2$Place)
## redorder the place by the population value of 2011
sdat3 <- (sdat2
  %>%  mutate(Place=forcats::fct_reorder(Place,Pop_2011)) ## create a factor level, reorder them by pop_2011 (so this is reorder and make them as factor at the same time)
)

str(sdat3$Place)
levels(sdat3$Place)

## (use desc(Pop_2011) to arrange in descending order of population):
(sdat3
    %>% arrange(desc(Pop_2011))
    %>% head()
)

##summarise by combinations of variables:
## Q: what is .groups="drop"?
(sdat3 
%>% group_by(year,Region) 
%>% summarise(across(homicide,mean),.groups="drop")  
%>% head()
  )

##What if I want the mean and standard error? R doesn’t have a built-in “standard error of the mean” function so I define one when I need it:
sem <- function(x) { sd(x)/sqrt(length(x)) }
region_avgs <- sdat3 %>% group_by(year,Region) %>%
    summarise(across(homicide,list(mean=~mean(.,na.rm=TRUE),
                                    sem=sem)),
              .groups="drop")
head(region_avgs)

## Question: why do I have NA values? Ans: only 1 sample is present
## Drilling down to check some values:
sdat3 %>% filter(year==2007 & Region=="all")

## Sometimes it’s useful to be able to go from long to wide format. pivot_wider() is the opposite of pivot_longer(): we specify a column in the current data set to spread out into new columns (key) and a column to use as the vales for the table (value)
(region_avgs
    %>% select(-homicide_sem)
    %>% pivot_wider(names_from=Region,values_from=homicide_mean)
    %>% head()
)

## save the results
saveRDS(sdat3,file="./data/CA_homicide.rds")

##Note: For analysis in R, it is generally best to keep your data in long format and pivot_wider() it as necessary (e.g. when creating a human-readable table for output).

#####################################################################################
##PART 2: Pictures
#####################################################################################
## load data
mdat <- readRDS("./data/CA_homicide.rds")

##One of the advantages of long format is that it allows us to use some of R’s more powerful graphics tools such as the ggplot2 and lattice packages (and it’s what most statistics packages expect):
library(ggplot2)
theme_set(theme_bw())  ## black-and-white theme
## set up basic plot:
p1 <- ggplot(mdat,aes(year,homicide,colour=Place))
## ggplot produces an R object which can then be printed (=displayed in a graphics window), or saved (or exported to a graphics file via ggsave()):
print(p1+geom_line())
print(p1+geom_line() +geom_point())
## Might be better on a log scale, with a sensible y-axis label:
p1L <- (p1
    + geom_line()
    + scale_y_log10()
    + labs(y="Homicides per 100,000 population")
)
print(p1L)

##Maybe we don’t care about time at all:
b1 <- (ggplot(mdat,aes(x=Place,y=homicide,
                       colour=Region))
    + geom_boxplot(outlier.colour=NULL)  ## set outlier points to same colour as boxes
    + scale_y_log10()
    + labs(y="Homicides per 100,000 population")
)
print(b1)
## The x-axis tick labels overlap enough to be unreadable (unless we resize the plot to be ridiculously long and narrow).
## We could rotate them 90 degrees to be vertical:
b1_vertlabels <- b1+theme(axis.text.x=element_text(angle=90))
print(b1_vertlabels)
## Note: In general if you want to tweak a ggplot plot, Google it or search the ggplot theme documentation or the ggplot cheat sheet for more information …

## Rotating the whole plot is less familiar, but arguably better. Here I’m also (1) changing the colour palette and (2) changing the order of the Place variable, using %+% to substitute a different set of data into an existing plot:
mdat_sort <- mdat %>% mutate(across(Place,~forcats::fct_reorder(.,homicide)))
print(b1
      %+% mdat_sort  ## substitute sorted data
      + coord_flip()      ## rotate entire plot
      + xlab("")          ## x-label redundant
      + scale_colour_brewer(palette="Dark2") ## change palette
      )

## Maybe we want to make our line graph less busy:
print(p1L+facet_wrap(~Region))

## We could also code population size by line width:
p2 <- (ggplot(mdat,
             aes(x=year,y=homicide,colour=Region,size=Pop_2011,
                 group=Place))
    + geom_line(alpha=0.5)
    + scale_y_log10()
    + scale_size_continuous(trans="log10")
    + labs(y="Homicides per 100,000 population")
)
print(p2)

## Using the directlabels package:
library(directlabels)
print(p1L
    + expand_limits(x=2014)  ## add a little more space
    + geom_dl(aes(label=Place),method="last.bumpup") 
    + theme(legend.position="none")  ## don't need the legend any more
)


```



## Class 6
Date: Feb 4, 2021

```{r Feb_4_class}
QMEEpath <- "~/classes/QMEE/docs/data/"
list.files(path=QMEEpath, pattern="*.csv") # create list of all .csv files in folder
## file <- "CA_homicide.csv"
## temp_dat <- read_csv(file = paste(QMEEpath,file, sep=''),col_types=cols()) 

## dealing with emty rows and cols
library(tidyverse)
library(janitor) # it says that 

## minimal reproduciable example
dd <- tibble(x=c(LETTERS[1:5],rep("",3)),
             y=c(1:5,rep(NA,3)),
             z=rep(NA,8)
             )

dd[-(6:7),-3]
## janitor lib
remove_empty(dd,c("rows","cols"))

##BMB to be 
emptyrows2 <- function(x){
  
} 

## or change the empty cells with NAs
dd %>% mutate_if(is.character,
                 ~replace(., which(!nzchar(.)),NA))
## ~ mean on fly, . means columns

?mutate_if

## the importance of clean data coding standards
tmp_table <- read.csv(text="
common_name_date
sunfish_2021
xx_2020
")
library(dplyr)
## letr's separate the column based on "_"
(tmp_table %>% separate(common_name_date,c("A","B"),sep="([_])")
          %>% head() #
)

library(skimr)

library(MASS)
m <- mvrnorm(50, mu=c(0,0),Sigma = matrix(c(2,1.5,1.5,2),2)) # corelated data set
plot(m[,1],m[,2])

m <- rbind(m,c(-2,2))
pairs(mtcars,gap=0) ## take the gaps out

## fancier than pairs
library(GGally)
ggpairs(mtcars)

library(car)



```


## Class 7
Date: Feb 9, 2021

- stats philosophy

## Class 8
Date: Feb 11, 2021

## Class 9 
```{r Feb_4_class}

library("ggplot2"); theme_set(theme_bw())
library("lmPerm")
library("coin")
library("gtools")

## Permutation
## dealing with emty rows and cols
library(tidyverse)

QMEEpath <- "~/classes/mcmaster/QMEE/docs/data/"
list.files(path=QMEEpath, pattern="*.csv") # create list of all .csv files in folder

file <- "ants.csv"
ants <- read_csv(file = paste(QMEEpath,file, sep=''),col_types=cols()) 
ants$place <- factor(ants$place)

## plots
ggplot(ants,aes(x=place,y=colonies))+geom_boxplot() + geom_point() 
## issue: boxplots don't make sense when you have a small data sets because they show you only 5 numbers (and outliers if they exist), so if you have only 4 data points. geom_point() is not very usefull since the points may overlap. I can jitter them but it may not look good
ggplot(ants,aes(x=place,y=colonies))+geom_boxplot() + geom_jitter()
## the trick is to use stat_sum, it looks whether there are multiple points at the same place: 
ggplot(ants,aes(x=place,y=colonies))+geom_boxplot() + stat_sum()
## see the notes

set.seed(101)
res <- numeric(9999) ## vector of zeros
for (i in 1:9999){
  ##scramble data
    ## calc statistics and save it, do that lots of times
  perm <- sample(nrow(ants))
  bdat <- transform(ants,colonies=colonies[perm]) ## transform is like mutate for base R
  ## the diff between the fields mean and forest's mean
  ## compute & store difference in means; store the value
  fieldmean <- mean(bdat[bdat$place=="field","colonies"])
  forestdmean <- mean(bdat[bdat$place=="forest","colonies"])
  res[i] <- fieldmean-forestdmean
}
hist(res)

truefieldmean <- mean(ants[ants$place=="field","colonies"])
trueforestdmean <- mean(ants[ants$place=="forest","colonies"])
obsval <- truefieldmean-trueforestdmean


## t test
tt <- t.test(colonies~place,data=ants,var.equal=TRUE)
tt$statistic

library(lmPerm)
summary(lm(colonies~place,data=ants))

## if I use lmPerm
m1 <- lmp(colonies~place,data=ants)
summary(m1)
## note the p-val is different since it is not relying on the distribution
## 

```

## Class 10

```{r Feb_25_class}

```

## Class 11

- general l model and generalized l model are different things,
- Basic linear model

This paper was suggested 
Karelus, Dana L, J Walter McCown, Brian K Scheick, Madelon van de Kerk, Benjamin M Bolker, and Madan K Oli. “Effects of Environmental Factors and Landscape Features on Movement Patterns of Florida Black Bears.” Journal of Mammalogy 98, no. 5 (October 3, 2017): 1463–78. https://doi.org/10.1093/jmammal/gyx066.

- Diagnostic of Linear Model;
  - dependancy assumption is very hard to check
  - many of the problems can be resolved by transformation of the data;
    - 
  - Box-Cox is always used on y, response var
  

```{r Mar_2_class}
library(tidyverse)
QMEEpath <- "~/classes/mcmaster/QMEE/docs/data/"
list.files(path=QMEEpath, pattern="*.csv") # create list of all .csv files in folder

file <- "skewdat.csv"
skewdata <- read_csv(file = paste(QMEEpath,file, sep=''),col_types=cols()) 

m1 <- lm(skew~Size, data=skewdata)
par(mfrow=c(2,2),mar=c(2,3,1.5,1),mgp=c(2,1,0))
plot(m1,id.n=4)


library(dplyr)

library(ggplot2); theme_set(theme_bw())
aa <- broom::augment(m1) %>% mutate(n=1:n())
(ggplot(skewdata, aes(Size,skew))
    + geom_point(aes(colour=abs(aa$.resid)>0.1))
    + geom_smooth(method="lm")
    + scale_colour_manual(values=c("black","red"))
)

## 
file2 <- "lizards.csv"
# lizards <- read_csv(file = paste(QMEEpath,file2, sep=''),col_types=cols())
lizards <- read.csv(file = paste(QMEEpath,file2, sep=''), stringsAsFactors=TRUE)

lizards$time <- factor(lizards$time,levels=c("early","midday","late"))
lmint <- lm(grahami~light*time, data=lizards)
lmboth <- lm(grahami~light + time, data=lizards)
lmlight <- lm(grahami~light, data=lizards)
lmtime <- lm(grahami~time, data=lizards)

anova(lmboth, lmlight, test="F")

anova(lmboth, lmtime, test="F")

drop1(lmboth, test="F")

car::Anova(lmboth)

print(summary(lmint))


```





